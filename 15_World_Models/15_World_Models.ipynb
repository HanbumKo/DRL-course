{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "World_Models.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOT0UUvIRxy2T1NyWqhT/kl",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/HanbumKo/DRL-course/blob/main/15_World_Models/15_World_Models.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JBMsA_ov1ufK"
      },
      "source": [
        "# World Models"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jUe7bSZ5Gk_-"
      },
      "source": [
        "Code based on [here](https://github.com/ctallec/world-models)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WBPaokjuQmrx",
        "outputId": "81a30fff-cad2-4e56-8c74-656a6f27f35e"
      },
      "source": [
        "!apt update\n",
        "!apt install xvfb\n",
        "!pip install gym[box2d]\n",
        "!pip install cma\n",
        "!pip install pyvirtualdisplay\n",
        "!pip install gym-notebook-wrapper\n",
        "!pip install ray\n",
        "!wget https://github.com/HanbumKo/DRL-course/raw/main/15_World_Models/weight/vae.pt\n",
        "!wget https://github.com/HanbumKo/DRL-course/raw/main/15_World_Models/weight/mdrnn.pt"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[33m\r0% [Working]\u001b[0m\r            \rHit:1 http://security.ubuntu.com/ubuntu bionic-security InRelease\n",
            "Hit:2 https://cloud.r-project.org/bin/linux/ubuntu bionic-cran40/ InRelease\n",
            "Ign:3 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  InRelease\n",
            "Ign:4 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  InRelease\n",
            "Hit:5 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Release\n",
            "Hit:6 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  Release\n",
            "Hit:7 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic InRelease\n",
            "Hit:8 http://archive.ubuntu.com/ubuntu bionic InRelease\n",
            "Hit:9 http://archive.ubuntu.com/ubuntu bionic-updates InRelease\n",
            "Hit:10 http://ppa.launchpad.net/cran/libgit2/ubuntu bionic InRelease\n",
            "Get:11 http://archive.ubuntu.com/ubuntu bionic-backports InRelease [74.6 kB]\n",
            "Hit:13 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu bionic InRelease\n",
            "Hit:15 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu bionic InRelease\n",
            "Fetched 74.6 kB in 2s (41.8 kB/s)\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "58 packages can be upgraded. Run 'apt list --upgradable' to see them.\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "xvfb is already the newest version (2:1.19.6-1ubuntu4.9).\n",
            "The following package was automatically installed and is no longer required:\n",
            "  libnvidia-common-460\n",
            "Use 'apt autoremove' to remove it.\n",
            "0 upgraded, 0 newly installed, 0 to remove and 58 not upgraded.\n",
            "Requirement already satisfied: gym[box2d] in /usr/local/lib/python3.7/dist-packages (0.17.3)\n",
            "Requirement already satisfied: cloudpickle<1.7.0,>=1.2.0 in /usr/local/lib/python3.7/dist-packages (from gym[box2d]) (1.3.0)\n",
            "Requirement already satisfied: pyglet<=1.5.0,>=1.4.0 in /usr/local/lib/python3.7/dist-packages (from gym[box2d]) (1.5.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from gym[box2d]) (1.4.1)\n",
            "Requirement already satisfied: numpy>=1.10.4 in /usr/local/lib/python3.7/dist-packages (from gym[box2d]) (1.19.5)\n",
            "Requirement already satisfied: box2d-py~=2.3.5; extra == \"box2d\" in /usr/local/lib/python3.7/dist-packages (from gym[box2d]) (2.3.8)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from pyglet<=1.5.0,>=1.4.0->gym[box2d]) (0.16.0)\n",
            "Requirement already satisfied: cma in /usr/local/lib/python3.7/dist-packages (3.0.3)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from cma) (1.19.5)\n",
            "Requirement already satisfied: pyvirtualdisplay in /usr/local/lib/python3.7/dist-packages (2.1)\n",
            "Requirement already satisfied: EasyProcess in /usr/local/lib/python3.7/dist-packages (from pyvirtualdisplay) (0.3)\n",
            "Requirement already satisfied: gym-notebook-wrapper in /usr/local/lib/python3.7/dist-packages (1.2.4)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from gym-notebook-wrapper) (3.2.2)\n",
            "Requirement already satisfied: ipython in /usr/local/lib/python3.7/dist-packages (from gym-notebook-wrapper) (5.5.0)\n",
            "Requirement already satisfied: gym in /usr/local/lib/python3.7/dist-packages (from gym-notebook-wrapper) (0.17.3)\n",
            "Requirement already satisfied: pyvirtualdisplay in /usr/local/lib/python3.7/dist-packages (from gym-notebook-wrapper) (2.1)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->gym-notebook-wrapper) (2.4.7)\n",
            "Requirement already satisfied: numpy>=1.11 in /usr/local/lib/python3.7/dist-packages (from matplotlib->gym-notebook-wrapper) (1.19.5)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->gym-notebook-wrapper) (2.8.1)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->gym-notebook-wrapper) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->gym-notebook-wrapper) (0.10.0)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.7/dist-packages (from ipython->gym-notebook-wrapper) (0.7.5)\n",
            "Requirement already satisfied: prompt-toolkit<2.0.0,>=1.0.4 in /usr/local/lib/python3.7/dist-packages (from ipython->gym-notebook-wrapper) (1.0.18)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.7/dist-packages (from ipython->gym-notebook-wrapper) (4.4.2)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.7/dist-packages (from ipython->gym-notebook-wrapper) (56.1.0)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.7/dist-packages (from ipython->gym-notebook-wrapper) (2.6.1)\n",
            "Requirement already satisfied: simplegeneric>0.8 in /usr/local/lib/python3.7/dist-packages (from ipython->gym-notebook-wrapper) (0.8.1)\n",
            "Requirement already satisfied: pexpect; sys_platform != \"win32\" in /usr/local/lib/python3.7/dist-packages (from ipython->gym-notebook-wrapper) (4.8.0)\n",
            "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.7/dist-packages (from ipython->gym-notebook-wrapper) (5.0.5)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from gym->gym-notebook-wrapper) (1.4.1)\n",
            "Requirement already satisfied: cloudpickle<1.7.0,>=1.2.0 in /usr/local/lib/python3.7/dist-packages (from gym->gym-notebook-wrapper) (1.3.0)\n",
            "Requirement already satisfied: pyglet<=1.5.0,>=1.4.0 in /usr/local/lib/python3.7/dist-packages (from gym->gym-notebook-wrapper) (1.5.0)\n",
            "Requirement already satisfied: EasyProcess in /usr/local/lib/python3.7/dist-packages (from pyvirtualdisplay->gym-notebook-wrapper) (0.3)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.1->matplotlib->gym-notebook-wrapper) (1.15.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->ipython->gym-notebook-wrapper) (0.2.5)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.7/dist-packages (from pexpect; sys_platform != \"win32\"->ipython->gym-notebook-wrapper) (0.7.0)\n",
            "Requirement already satisfied: ipython-genutils in /usr/local/lib/python3.7/dist-packages (from traitlets>=4.2->ipython->gym-notebook-wrapper) (0.2.0)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from pyglet<=1.5.0,>=1.4.0->gym->gym-notebook-wrapper) (0.16.0)\n",
            "Requirement already satisfied: ray in /usr/local/lib/python3.7/dist-packages (1.3.0)\n",
            "Requirement already satisfied: protobuf>=3.15.3 in /usr/local/lib/python3.7/dist-packages (from ray) (3.16.0)\n",
            "Requirement already satisfied: prometheus-client>=0.7.1 in /usr/local/lib/python3.7/dist-packages (from ray) (0.10.1)\n",
            "Requirement already satisfied: aioredis in /usr/local/lib/python3.7/dist-packages (from ray) (1.3.1)\n",
            "Requirement already satisfied: gpustat in /usr/local/lib/python3.7/dist-packages (from ray) (0.6.0)\n",
            "Requirement already satisfied: jsonschema in /usr/local/lib/python3.7/dist-packages (from ray) (2.6.0)\n",
            "Requirement already satisfied: msgpack<2.0.0,>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from ray) (1.0.2)\n",
            "Requirement already satisfied: click>=7.0 in /usr/local/lib/python3.7/dist-packages (from ray) (7.1.2)\n",
            "Requirement already satisfied: grpcio>=1.28.1 in /usr/local/lib/python3.7/dist-packages (from ray) (1.32.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from ray) (3.0.12)\n",
            "Requirement already satisfied: redis>=3.5.0 in /usr/local/lib/python3.7/dist-packages (from ray) (3.5.3)\n",
            "Requirement already satisfied: opencensus in /usr/local/lib/python3.7/dist-packages (from ray) (0.7.12)\n",
            "Requirement already satisfied: colorama in /usr/local/lib/python3.7/dist-packages (from ray) (0.4.4)\n",
            "Requirement already satisfied: py-spy>=0.2.0 in /usr/local/lib/python3.7/dist-packages (from ray) (0.3.6)\n",
            "Requirement already satisfied: numpy>=1.16 in /usr/local/lib/python3.7/dist-packages (from ray) (1.19.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.7/dist-packages (from ray) (3.13)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from ray) (2.23.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.7/dist-packages (from ray) (3.7.4.post0)\n",
            "Requirement already satisfied: aiohttp-cors in /usr/local/lib/python3.7/dist-packages (from ray) (0.7.0)\n",
            "Requirement already satisfied: six>=1.9 in /usr/local/lib/python3.7/dist-packages (from protobuf>=3.15.3->ray) (1.15.0)\n",
            "Requirement already satisfied: async-timeout in /usr/local/lib/python3.7/dist-packages (from aioredis->ray) (3.0.1)\n",
            "Requirement already satisfied: hiredis in /usr/local/lib/python3.7/dist-packages (from aioredis->ray) (2.0.0)\n",
            "Requirement already satisfied: nvidia-ml-py3>=7.352.0 in /usr/local/lib/python3.7/dist-packages (from gpustat->ray) (7.352.0)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.7/dist-packages (from gpustat->ray) (5.4.8)\n",
            "Requirement already satisfied: blessings>=1.6 in /usr/local/lib/python3.7/dist-packages (from gpustat->ray) (1.7)\n",
            "Requirement already satisfied: google-api-core<2.0.0,>=1.0.0 in /usr/local/lib/python3.7/dist-packages (from opencensus->ray) (1.26.3)\n",
            "Requirement already satisfied: opencensus-context==0.1.2 in /usr/local/lib/python3.7/dist-packages (from opencensus->ray) (0.1.2)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->ray) (2020.12.5)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->ray) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->ray) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->ray) (2.10)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->ray) (20.3.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.5 in /usr/local/lib/python3.7/dist-packages (from aiohttp->ray) (3.7.4.3)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.7/dist-packages (from aiohttp->ray) (1.6.3)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.7/dist-packages (from aiohttp->ray) (5.1.0)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0dev,>=1.6.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core<2.0.0,>=1.0.0->opencensus->ray) (1.53.0)\n",
            "Requirement already satisfied: google-auth<2.0dev,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from google-api-core<2.0.0,>=1.0.0->opencensus->ray) (1.28.1)\n",
            "Requirement already satisfied: setuptools>=40.3.0 in /usr/local/lib/python3.7/dist-packages (from google-api-core<2.0.0,>=1.0.0->opencensus->ray) (56.1.0)\n",
            "Requirement already satisfied: pytz in /usr/local/lib/python3.7/dist-packages (from google-api-core<2.0.0,>=1.0.0->opencensus->ray) (2018.9)\n",
            "Requirement already satisfied: packaging>=14.3 in /usr/local/lib/python3.7/dist-packages (from google-api-core<2.0.0,>=1.0.0->opencensus->ray) (20.9)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4; python_version >= \"3.6\" in /usr/local/lib/python3.7/dist-packages (from google-auth<2.0dev,>=1.21.1->google-api-core<2.0.0,>=1.0.0->opencensus->ray) (4.7.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.7/dist-packages (from google-auth<2.0dev,>=1.21.1->google-api-core<2.0.0,>=1.0.0->opencensus->ray) (0.2.8)\n",
            "Requirement already satisfied: cachetools<5.0,>=2.0.0 in /usr/local/lib/python3.7/dist-packages (from google-auth<2.0dev,>=1.21.1->google-api-core<2.0.0,>=1.0.0->opencensus->ray) (4.2.1)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=14.3->google-api-core<2.0.0,>=1.0.0->opencensus->ray) (2.4.7)\n",
            "Requirement already satisfied: pyasn1>=0.1.3 in /usr/local/lib/python3.7/dist-packages (from rsa<5,>=3.1.4; python_version >= \"3.6\"->google-auth<2.0dev,>=1.21.1->google-api-core<2.0.0,>=1.0.0->opencensus->ray) (0.4.8)\n",
            "--2021-05-11 08:20:14--  https://github.com/HanbumKo/DRL-course/raw/main/15_World_Models/weight/vae.pt\n",
            "Resolving github.com (github.com)... 140.82.114.3\n",
            "Connecting to github.com (github.com)|140.82.114.3|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/HanbumKo/DRL-course/main/15_World_Models/weight/vae.pt [following]\n",
            "--2021-05-11 08:20:14--  https://raw.githubusercontent.com/HanbumKo/DRL-course/main/15_World_Models/weight/vae.pt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.110.133, 185.199.109.133, 185.199.111.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.110.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 17401909 (17M) [application/octet-stream]\n",
            "Saving to: ‘vae.pt.3’\n",
            "\n",
            "vae.pt.3            100%[===================>]  16.60M  --.-KB/s    in 0.09s   \n",
            "\n",
            "2021-05-11 08:20:14 (190 MB/s) - ‘vae.pt.3’ saved [17401909/17401909]\n",
            "\n",
            "--2021-05-11 08:20:14--  https://github.com/HanbumKo/DRL-course/raw/main/15_World_Models/weight/mdrnn.pt\n",
            "Resolving github.com (github.com)... 140.82.114.3\n",
            "Connecting to github.com (github.com)|140.82.114.3|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/HanbumKo/DRL-course/main/15_World_Models/weight/mdrnn.pt [following]\n",
            "--2021-05-11 08:20:14--  https://raw.githubusercontent.com/HanbumKo/DRL-course/main/15_World_Models/weight/mdrnn.pt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1538058 (1.5M) [application/octet-stream]\n",
            "Saving to: ‘mdrnn.pt.3’\n",
            "\n",
            "mdrnn.pt.3          100%[===================>]   1.47M  --.-KB/s    in 0.02s   \n",
            "\n",
            "2021-05-11 08:20:15 (81.5 MB/s) - ‘mdrnn.pt.3’ saved [1538058/1538058]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IVYgBnErQaUt",
        "outputId": "5466e017-d49d-4ce8-f567-0ec64c7a2873"
      },
      "source": [
        "import gym\n",
        "import sys\n",
        "import ray\n",
        "import cv2\n",
        "import cma\n",
        "import time\n",
        "import torch\n",
        "import random\n",
        "import gnwrapper\n",
        "import numpy as np\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "\n",
        "from gym import wrappers\n",
        "from torchvision import transforms\n",
        "from torch.distributions.normal import Normal\n",
        "from torch.multiprocessing import Process, Queue\n",
        "from os import mkdir, unlink, listdir, getpid\n",
        "from os.path import join, exists\n",
        "\n",
        "from IPython.display import clear_output\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ray/autoscaler/_private/cli_logger.py:61: FutureWarning: Not all Ray CLI dependencies were found. In Ray 1.4+, the Ray CLI, autoscaler, and dashboard will only be usable via `pip install 'ray[default]'`. Please update your install command.\n",
            "  \"update your install command.\", FutureWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vATCxPmlGEZ5"
      },
      "source": [
        "def show_image(image):\n",
        "    if isinstance(image, torch.Tensor):\n",
        "        image = image.numpy()\n",
        "    clear_output(True)\n",
        "    plt.imshow(image)\n",
        "    plt.show()"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zTK_ImWTOgES"
      },
      "source": [
        "def show_two_images(image1, image2):\n",
        "    if isinstance(image1, torch.Tensor):\n",
        "        image1 = image1.detach().numpy()\n",
        "    if isinstance(image2, torch.Tensor):\n",
        "        image2 = image2.detach().numpy()\n",
        "    image = np.concatenate((image1, image2), axis=1)\n",
        "    clear_output(True)\n",
        "    plt.imshow(image)\n",
        "    plt.show()"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qOKRZj4v-g86",
        "outputId": "14369d21-1125-411d-cf11-9cd4dd3c7dba"
      },
      "source": [
        "env = gym.make(\"CarRacing-v0\")\n",
        "env = gnwrapper.LoopAnimation(env)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
            "  warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZBxci_JfOfcW"
      },
      "source": [
        "# VAE rollout data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gHJphGsII47G"
      },
      "source": [
        "rollout_length = 10000\n",
        "observations = np.zeros((rollout_length, 64, 64, 3))\n",
        "actions = np.zeros((rollout_length, 3))"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y9av72zxQfWY"
      },
      "source": [
        "obs = env.reset()\n",
        "for i in range(rollout_length):\n",
        "    action = env.action_space.sample() # Take random action\n",
        "    obs = cv2.resize(obs, dsize=(64, 64), interpolation=cv2.INTER_CUBIC)\n",
        "    observations[i, :, :, :] = obs\n",
        "    actions[i, :] = action\n",
        "    obs, rew, done, _ = env.step(action)\n",
        "    # print(i)\n",
        "    if done:\n",
        "        obs = env.reset()\n",
        "\n",
        "observations = np.transpose(observations, (0, 3, 1, 2)) / 255.\n",
        "np.save('observations.npy', observations)\n",
        "np.save('actions.npy', actions)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bQmT4epBKzWf"
      },
      "source": [
        "obs_data = np.load('data/observations.npy')\n",
        "act_data = np.load('data/actions.npy')\n",
        "print(obs_data.shape)\n",
        "print(act_data.shape)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5r6dLRVT_Zn5"
      },
      "source": [
        "# V model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mED00ERWRIfD"
      },
      "source": [
        "class Decoder(nn.Module):\n",
        "    \"\"\" VAE decoder \"\"\"\n",
        "    def __init__(self, img_channels, latent_size):\n",
        "        super(Decoder, self).__init__()\n",
        "        self.latent_size = latent_size\n",
        "        self.img_channels = img_channels\n",
        "\n",
        "        self.fc1 = nn.Linear(latent_size, 1024)\n",
        "        self.deconv1 = nn.ConvTranspose2d(1024, 128, 5, stride=2)\n",
        "        self.deconv2 = nn.ConvTranspose2d(128, 64, 5, stride=2)\n",
        "        self.deconv3 = nn.ConvTranspose2d(64, 32, 6, stride=2)\n",
        "        self.deconv4 = nn.ConvTranspose2d(32, img_channels, 6, stride=2)\n",
        "\n",
        "    def forward(self, x): # pylint: disable=arguments-differ\n",
        "        x = F.relu(self.fc1(x))\n",
        "        x = x.unsqueeze(-1).unsqueeze(-1)\n",
        "        x = F.relu(self.deconv1(x))\n",
        "        x = F.relu(self.deconv2(x))\n",
        "        x = F.relu(self.deconv3(x))\n",
        "        reconstruction = F.sigmoid(self.deconv4(x))\n",
        "        return reconstruction"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kDShVuQLQkoe"
      },
      "source": [
        "class Encoder(nn.Module): # pylint: disable=too-many-instance-attributes\n",
        "    \"\"\" VAE encoder \"\"\"\n",
        "    def __init__(self, img_channels, latent_size):\n",
        "        super(Encoder, self).__init__()\n",
        "        self.latent_size = latent_size\n",
        "        #self.img_size = img_size\n",
        "        self.img_channels = img_channels\n",
        "\n",
        "        self.conv1 = nn.Conv2d(img_channels, 32, 4, stride=2)\n",
        "        self.conv2 = nn.Conv2d(32, 64, 4, stride=2)\n",
        "        self.conv3 = nn.Conv2d(64, 128, 4, stride=2)\n",
        "        self.conv4 = nn.Conv2d(128, 256, 4, stride=2)\n",
        "\n",
        "        self.fc_mu = nn.Linear(2*2*256, latent_size)\n",
        "        self.fc_logsigma = nn.Linear(2*2*256, latent_size)\n",
        "\n",
        "\n",
        "    def forward(self, x): # pylint: disable=arguments-differ\n",
        "        x = F.relu(self.conv1(x))\n",
        "        x = F.relu(self.conv2(x))\n",
        "        x = F.relu(self.conv3(x))\n",
        "        x = F.relu(self.conv4(x))\n",
        "        x = x.reshape(x.size(0), -1)\n",
        "\n",
        "        mu = self.fc_mu(x)\n",
        "        logsigma = self.fc_logsigma(x)\n",
        "\n",
        "        return mu, logsigma"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8t-7EZZCREE9"
      },
      "source": [
        "class VAE(nn.Module):\n",
        "    \"\"\" Variational Autoencoder \"\"\"\n",
        "    def __init__(self, img_channels, latent_size):\n",
        "        super(VAE, self).__init__()\n",
        "        self.encoder = Encoder(img_channels, latent_size)\n",
        "        self.decoder = Decoder(img_channels, latent_size)\n",
        "\n",
        "    def forward(self, x): # pylint: disable=arguments-differ\n",
        "        mu, logsigma = self.encoder(x)\n",
        "        sigma = logsigma.exp()\n",
        "        eps = torch.randn_like(sigma)\n",
        "        z = eps.mul(sigma).add_(mu)\n",
        "\n",
        "        recon_x = self.decoder(z)\n",
        "        return recon_x, mu, logsigma"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NGaaBLYeAJQ9"
      },
      "source": [
        "# Reconstruction + KL divergence losses summed over all elements and batch\n",
        "def vae_loss_function(recon_x, x, mu, logsigma):\n",
        "    \"\"\" VAE loss function \"\"\"\n",
        "    BCE = F.mse_loss(recon_x, x, size_average=False)\n",
        "\n",
        "    # see Appendix B from VAE paper:\n",
        "    # Kingma and Welling. Auto-Encoding Variational Bayes. ICLR, 2014\n",
        "    # https://arxiv.org/abs/1312.6114\n",
        "    # 0.5 * sum(1 + log(sigma^2) - mu^2 - sigma^2)\n",
        "    KLD = -0.5 * torch.sum(1 + 2 * logsigma - mu.pow(2) - (2 * logsigma).exp())\n",
        "    return BCE + KLD"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XnrWONCvEkQ-",
        "outputId": "61aa6319-9eb1-4ff6-a4ce-59f413d5e775"
      },
      "source": [
        "vae = VAE(3, 32).to(device)\n",
        "optimizer = optim.Adam(vae.parameters())\n",
        "batch_size = 128\n",
        "vae.load_state_dict(torch.load(\"vae.pt\", map_location=device))"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dbk6m3uUAg4C"
      },
      "source": [
        "def train_vae():\n",
        "    vae.train()\n",
        "    idxs = np.random.randint(0, rollout_length, size=batch_size)\n",
        "    data = observations[idxs]\n",
        "    data = torch.as_tensor(data, dtype=torch.float32).to(device)\n",
        "    recon_batch, mu, logvar = vae(data)\n",
        "    optimizer.zero_grad()\n",
        "    loss = loss_function(recon_batch, data, mu, logvar)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "    # print(\"Train loss :\", loss.item() / batch_size)\n"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tMJ-5k-gGUf2"
      },
      "source": [
        "def test_vae():\n",
        "    vae.eval()\n",
        "    with torch.no_grad():\n",
        "        data = torch.as_tensor(observations, dtype=torch.float32).to(device)\n",
        "        recon_batch, mu, logvar = vae(data)\n",
        "        test_loss = loss_function(recon_batch, data, mu, logvar).item() / data.shape[0]\n",
        "        print(\"Test loss :\", test_loss)"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d_kq79ehG6yg"
      },
      "source": [
        "for epoch in range(100000):\n",
        "    train_vae()\n",
        "    if epoch % 1000 == 0:\n",
        "        print(epoch)\n",
        "        test_vae()"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ycPp6QJ-vyDF"
      },
      "source": [
        "torch.save(vae.state_dict(), \"vae.pt\")"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4hRicspbHFm-"
      },
      "source": [
        "data = torch.as_tensor(observations, dtype=torch.float32).to(device)\n",
        "with torch.no_grad():\n",
        "    output, _, _ = vae(data)\n",
        "    data = data.cpu().permute(0, 2, 3, 1)\n",
        "    output = output.cpu().permute(0, 2, 3, 1)\n",
        "    for _ in range(10):\n",
        "        i = random.randint(0, data.shape[0])\n",
        "        show_two_images(data[i], output[i])\n",
        "        time.sleep(1)\n"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y0QEHQyUyElt"
      },
      "source": [
        "# M model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p7PgoN2PZPdv"
      },
      "source": [
        "class MDRNNCell(nn.Module):\n",
        "    \"\"\" MDRNN model for one step forward \"\"\"\n",
        "    def __init__(self, latents, actions, hiddens, gaussians):\n",
        "        super().__init__()\n",
        "        self.latents = latents\n",
        "        self.actions = actions\n",
        "        self.hiddens = hiddens\n",
        "        self.gaussians = gaussians\n",
        "\n",
        "        self.gmm_linear = nn.Linear(hiddens, (2*latents + 1)*gaussians + 2)\n",
        "        self.rnn = nn.LSTMCell(latents + actions, hiddens)\n",
        "\n",
        "    def forward(self, action, latent, hidden): # pylint: disable=arguments-differ\n",
        "        in_al = torch.cat([action, latent], dim=1)\n",
        "\n",
        "        next_hidden = self.rnn(in_al, hidden)\n",
        "        out_rnn = next_hidden[0]\n",
        "\n",
        "        out_full = self.gmm_linear(out_rnn)\n",
        "\n",
        "        stride = self.gaussians * self.latents\n",
        "\n",
        "        mus = out_full[:, :stride]\n",
        "        mus = mus.view(-1, self.gaussians, self.latents)\n",
        "\n",
        "        sigmas = out_full[:, stride:2 * stride]\n",
        "        sigmas = sigmas.view(-1, self.gaussians, self.latents)\n",
        "        sigmas = torch.exp(sigmas)\n",
        "\n",
        "        pi = out_full[:, 2 * stride:2 * stride + self.gaussians]\n",
        "        pi = pi.view(-1, self.gaussians)\n",
        "        logpi = f.log_softmax(pi, dim=-1)\n",
        "\n",
        "        r = out_full[:, -2]\n",
        "\n",
        "        d = out_full[:, -1]\n",
        "\n",
        "        return mus, sigmas, logpi, r, d, next_hidden"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rvh-aokTKtAQ"
      },
      "source": [
        "class MDRNN(nn.Module):\n",
        "    def __init__(self, latents, actions, hiddens, gaussians):\n",
        "        super().__init__()\n",
        "        self.latents = latents\n",
        "        self.actions = actions\n",
        "        self.hiddens = hiddens\n",
        "        self.gaussians = gaussians\n",
        "\n",
        "        self.gmm_linear = nn.Linear(hiddens, (2*latents + 1)*gaussians + 2)\n",
        "        self.rnn = nn.LSTM(latents + actions, hiddens)\n",
        "    \n",
        "    def forward(self, actions, latents):\n",
        "        # actions: (sequence_length, batch_size, action_size)\n",
        "        # latents: (sequence_length, batch_size, latent_size)\n",
        "        seq_len, bs = actions.shape[0], actions.shape[1]\n",
        "        \n",
        "        ins = torch.cat([actions, latents], dim=-1)\n",
        "        outs, _ = self.rnn(ins)\n",
        "        gmm_outs = self.gmm_linear(outs)\n",
        "\n",
        "        stride = self.gaussians * self.latents\n",
        "        \n",
        "        mus = gmm_outs[:, :, :stride]\n",
        "        mus = mus.view(seq_len, bs, self.gaussians, self.latents)\n",
        "\n",
        "        sigmas = gmm_outs[:, :, stride:2 * stride]\n",
        "        sigmas = sigmas.view(seq_len, bs, self.gaussians, self.latents)\n",
        "        sigmas = torch.exp(sigmas)\n",
        "\n",
        "        pi = gmm_outs[:, :, 2 * stride: 2 * stride + self.gaussians]\n",
        "        pi = pi.view(seq_len, bs, self.gaussians)\n",
        "        logpi = F.log_softmax(pi, dim=-1)\n",
        "\n",
        "        rs = gmm_outs[:, :, -2]\n",
        "\n",
        "        ds = gmm_outs[:, :, -1]\n",
        "\n",
        "        return mus, sigmas, logpi, rs, ds"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KhDBQ04YI25J"
      },
      "source": [
        "@ray.remote\n",
        "def mdrnn_rollout():\n",
        "    o = np.zeros((1000, 64, 64, 3))\n",
        "    a = np.zeros((1000, 3))\n",
        "    r = np.zeros((1000, ))\n",
        "    d = np.zeros((1000, ))\n",
        "    o2 = np.zeros((1000, 64, 64, 3))\n",
        "\n",
        "    env = gym.make(\"CarRacing-v0\")\n",
        "    env = gnwrapper.LoopAnimation(env)\n",
        "\n",
        "    obs = env.reset()\n",
        "    for i in range(1000):\n",
        "        action = env.action_space.sample() # Take random action\n",
        "        next_obs, rew, done, _ = env.step(action)\n",
        "\n",
        "        obs = cv2.resize(obs, dsize=(64, 64), interpolation=cv2.INTER_CUBIC)\n",
        "        next_obs = cv2.resize(next_obs, dsize=(64, 64), interpolation=cv2.INTER_CUBIC)\n",
        "\n",
        "        o[i, :, :, :] = obs / 255.\n",
        "        a[i, :] = action\n",
        "        r[i] = rew\n",
        "        d[i] = done\n",
        "        o2[i, :, :, :] = next_obs / 255.\n",
        "\n",
        "        obs = next_obs\n",
        "\n",
        "        if done:\n",
        "            pass\n",
        "            # obs = env.reset()\n",
        "        \n",
        "    return o, a, r, d, o2"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WWDiK37oC3DC",
        "outputId": "18ecff82-f56d-42eb-ee8f-4441a917e932"
      },
      "source": [
        "ray.init()"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2021-05-11 08:20:21,467\tINFO services.py:1269 -- View the Ray dashboard at \u001b[1m\u001b[32mhttp://127.0.0.1:8265\u001b[39m\u001b[22m\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'metrics_export_port': 65105,\n",
              " 'node_id': '4ad3d15f5d06f2510f571d1f42eece9849f234777b4254b3f8943d39',\n",
              " 'node_ip_address': '172.28.0.2',\n",
              " 'object_store_address': '/tmp/ray/session_2021-05-11_08-20-19_568358_4254/sockets/plasma_store',\n",
              " 'raylet_ip_address': '172.28.0.2',\n",
              " 'raylet_socket_name': '/tmp/ray/session_2021-05-11_08-20-19_568358_4254/sockets/raylet',\n",
              " 'redis_address': '172.28.0.2:6379',\n",
              " 'session_dir': '/tmp/ray/session_2021-05-11_08-20-19_568358_4254',\n",
              " 'webui_url': '127.0.0.1:8265'}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-QZw4o-pSh6X"
      },
      "source": [
        "mdrnn = MDRNN(latents=32, actions=3, hiddens=256, gaussians=5)\n",
        "mdrnn.to(device)\n",
        "mdrnn.load_state_dict(torch.load(\"mdrnn.pt\", map_location=device))\n",
        "optimizer = torch.optim.RMSprop(mdrnn.parameters(), lr=1e-3, alpha=.9)"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WXTM_Ljf-6Vx"
      },
      "source": [
        "def gmm_loss(batch, mus, sigmas, logpi, reduce=True): # pylint: disable=too-many-arguments\n",
        "    \"\"\" Computes the gmm loss.\n",
        "    Compute minus the log probability of batch under the GMM model described\n",
        "    by mus, sigmas, pi. Precisely, with bs1, bs2, ... the sizes of the batch\n",
        "    dimensions (several batch dimension are useful when you have both a batch\n",
        "    axis and a time step axis), gs the number of mixtures and fs the number of\n",
        "    features.\n",
        "    :args batch: (bs1, bs2, *, fs) torch tensor\n",
        "    :args mus: (bs1, bs2, *, gs, fs) torch tensor\n",
        "    :args sigmas: (bs1, bs2, *, gs, fs) torch tensor\n",
        "    :args logpi: (bs1, bs2, *, gs) torch tensor\n",
        "    :args reduce: if not reduce, the mean in the following formula is ommited\n",
        "    :returns:\n",
        "    loss(batch) = - mean_{i1=0..bs1, i2=0..bs2, ...} log(\n",
        "        sum_{k=1..gs} pi[i1, i2, ..., k] * N(\n",
        "            batch[i1, i2, ..., :] | mus[i1, i2, ..., k, :], sigmas[i1, i2, ..., k, :]))\n",
        "    NOTE: The loss is not reduced along the feature dimension (i.e. it should scale ~linearily\n",
        "    with fs).\n",
        "    \"\"\"\n",
        "    batch = batch.unsqueeze(-2)\n",
        "    normal_dist = Normal(mus, sigmas)\n",
        "    g_log_probs = normal_dist.log_prob(batch)\n",
        "    g_log_probs = logpi + torch.sum(g_log_probs, dim=-1)\n",
        "    max_log_probs = torch.max(g_log_probs, dim=-1, keepdim=True)[0]\n",
        "    g_log_probs = g_log_probs - max_log_probs\n",
        "\n",
        "    g_probs = torch.exp(g_log_probs)\n",
        "    probs = torch.sum(g_probs, dim=-1)\n",
        "\n",
        "    log_prob = max_log_probs.squeeze() + torch.log(probs)\n",
        "    if reduce:\n",
        "        return - torch.mean(log_prob)\n",
        "    return - log_prob"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mKc6H1HyWIFQ"
      },
      "source": [
        "def to_latent(obs, next_obs):\n",
        "    # obs: (sequence length, width, height, 3) \n",
        "    # next_obs: (sequence length, width, height, 3)\n",
        "    obs = obs.permute(0, 3, 1, 2)\n",
        "    next_obs = next_obs.permute(0, 3, 1, 2)\n",
        "\n",
        "    recon1, obs_mu, obs_logsigma = vae(obs)\n",
        "    recon2, next_obs_mu, next_obs_logsigma = vae(next_obs)\n",
        "\n",
        "    # eps = torch.randn_like(obs_logsigma)\n",
        "    latent_obs = obs_mu + obs_logsigma.exp() * torch.randn_like(obs_mu)\n",
        "\n",
        "    # eps = torch.randn_like(next_obs_logsigma)\n",
        "    latent_next_obs = next_obs_mu + next_obs_logsigma.exp() * torch.randn_like(next_obs_mu)\n",
        "\n",
        "    return latent_obs, latent_next_obs"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uZ_Z0MAqOpcB"
      },
      "source": [
        "def get_loss(latent_obs, action, reward, terminal, latent_next_obs):\n",
        "    # :args latent_obs: (BSIZE, SEQ_LEN, LSIZE) torch tensor\n",
        "    # :args action: (BSIZE, SEQ_LEN, ASIZE) torch tensor\n",
        "    # :args reward: (BSIZE, SEQ_LEN) torch tensor\n",
        "    # :args terminal: (BSIZE, SEQ_LEN) torch tensor\n",
        "    # :args latent_next_obs: (BSIZE, SEQ_LEN, LSIZE) torch tensor\n",
        "    latent_obs, action,\\\n",
        "        reward, terminal,\\\n",
        "        latent_next_obs = [arr.transpose(1, 0)\n",
        "                            for arr in [latent_obs, action,\n",
        "                                        reward, terminal,\n",
        "                                        latent_next_obs]]\n",
        "    mus, sigmas, logpi, rs, ds = mdrnn(action, latent_obs)\n",
        "    gmm = gmm_loss(latent_next_obs, mus, sigmas, logpi)\n",
        "    bce = F.binary_cross_entropy_with_logits(ds, terminal)\n",
        "    mse = F.mse_loss(rs, reward)\n",
        "    scale = 34\n",
        "    # print(\"gmm :\", gmm)\n",
        "    # print(\"bce :\", bce)\n",
        "    # print(\"mse :\", mse)\n",
        "    loss = (gmm + bce + mse) / scale\n",
        "    return loss\n"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hr7IvpX6_PYd"
      },
      "source": [
        "def train():\n",
        "    mdrnn.train()\n",
        "    rollout_ops = [mdrnn_rollout.remote() for _ in range(n_workers)]\n",
        "    res = ray.get(rollout_ops)\n",
        "    o = np.array(())\n",
        "    loss_sum = 0.\n",
        "    for i in range(n_workers):\n",
        "        o, a, r, d, o2 = res[i]\n",
        "\n",
        "        o = torch.as_tensor(o, dtype=torch.float32).to(device)\n",
        "        a = torch.as_tensor(a, dtype=torch.float32).to(device)\n",
        "        r = torch.as_tensor(r, dtype=torch.float32).to(device)\n",
        "        d = torch.as_tensor(d, dtype=torch.float32).to(device)\n",
        "        o2 = torch.as_tensor(o2, dtype=torch.float32).to(device)\n",
        "\n",
        "        # o: (1000, 64, 64, 3)\n",
        "        # a: (1000, 3)\n",
        "        # r: (1000, )\n",
        "        # d: (1000, )\n",
        "        # o2: (1000, 64, 64, 3)\n",
        "\n",
        "        latent_obs, latent_next_obs = to_latent(o, o2)\n",
        "        # latent_obs: (1000, 32)\n",
        "        # latent_next_obs: (1000, 32)\n",
        "\n",
        "        latent_obs = latent_obs.unsqueeze(0)\n",
        "        a = a.unsqueeze(0)\n",
        "        r = r.unsqueeze(0)\n",
        "        d = d.unsqueeze(0)\n",
        "        latent_next_obs = latent_next_obs.unsqueeze(0)\n",
        "\n",
        "        loss = get_loss(latent_obs, a, r, d, latent_next_obs)\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        loss_sum += loss.item()\n",
        "    print()\n",
        "    print(\"=\"*60)\n",
        "    print(loss_sum/n_workers)\n",
        "    print(\"=\"*60)\n",
        "    print()\n",
        "\n",
        "    torch.save(mdrnn.state_dict(), \"mdrnn.pt\")\n"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5YulGMzRJZHf"
      },
      "source": [
        "for _ in range(10000000):\n",
        "    train()"
      ],
      "execution_count": 28,
      "outputs": []
    }
  ]
}